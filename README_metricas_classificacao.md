# ðŸ“Š Projeto: CÃ¡lculo de MÃ©tricas de AvaliaÃ§Ã£o para ClassificaÃ§Ã£o

Este projeto demonstra o cÃ¡lculo manual das principais **mÃ©tricas de avaliaÃ§Ã£o** utilizadas em algoritmos de **classificaÃ§Ã£o binÃ¡ria**, com base em uma **matriz de confusÃ£o arbitrÃ¡ria**.

---

## âœ… MÃ©tricas Implementadas

| MÃ©trica         | FÃ³rmula |
|------------------|---------|
| **AcurÃ¡cia**     | (VP + VN) / (VP + VN + FP + FN) |
| **Sensibilidade** (Recall) | VP / (VP + FN) |
| **Especificidade** | VN / (VN + FP) |
| **PrecisÃ£o**     | VP / (VP + FP) |
| **F1-Score**     | 2 Ã— (PrecisÃ£o Ã— Recall) / (PrecisÃ£o + Recall) |

---

## ðŸ“¦ Exemplo de Matriz de ConfusÃ£o

|                | Predito Positivo | Predito Negativo |
|----------------|------------------|------------------|
| Real Positivo  | VP = 50          | FN = 10          |
| Real Negativo  | FP = 5           | VN = 35          |

---

## ðŸ§  CÃ³digo Python

```python
def calcular_metricas(vp, vn, fp, fn):
    total = vp + vn + fp + fn

    acuracia = (vp + vn) / total if total > 0 else 0
    sensibilidade = vp / (vp + fn) if (vp + fn) > 0 else 0
    especificidade = vn / (vn + fp) if (vn + fp) > 0 else 0
    precisao = vp / (vp + fp) if (vp + fp) > 0 else 0
    f1_score = (2 * precisao * sensibilidade) / (precisao + sensibilidade) if (precisao + sensibilidade) > 0 else 0

    return {
        "AcurÃ¡cia": round(acuracia, 4),
        "Sensibilidade (Recall)": round(sensibilidade, 4),
        "Especificidade": round(especificidade, 4),
        "PrecisÃ£o": round(precisao, 4),
        "F1-Score": round(f1_score, 4)
    }

# Exemplo
vp, vn, fp, fn = 50, 35, 5, 10
metricas = calcular_metricas(vp, vn, fp, fn)

for nome, valor in metricas.items():
    print(f"{nome}: {valor}")
```

---

## ðŸ“¥ Requisitos

```bash
pip install jupyter notebook
```

